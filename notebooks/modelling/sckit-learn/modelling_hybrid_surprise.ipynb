{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load datasets\n",
    "recipes_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/recipes_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(recipes_df['Ingredients'])\n",
    "\n",
    "def get_content_based_recommendations(user_ingredients, top_n=10):\n",
    "    user_tfidf = tfidf_vectorizer.transform([user_ingredients])\n",
    "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    similar_indices = cosine_sim.argsort().flatten()[::-1][:top_n]\n",
    "    return recipes_df.iloc[similar_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      recipeId                     Category  \\\n",
      "79          80                    Appetizer   \n",
      "246        247                    Breakfast   \n",
      "936        937                  Main Course   \n",
      "1016      1017              Sauce,Side Dish   \n",
      "49          50                      Dessert   \n",
      "61          62  Appetizer,Breakfast,Dessert   \n",
      "9           10                    Appetizer   \n",
      "71          72                    Appetizer   \n",
      "490        491                      Dessert   \n",
      "653        654                      Dessert   \n",
      "\n",
      "                                                  Title  Total Time  \\\n",
      "79    Warm Brie with Honeyed Cranberry Walnut Fruit ...          15   \n",
      "246                     Cranberry Orange Muffins Recipe          30   \n",
      "936                  Cranberry Orange Glazed Ham Recipe          95   \n",
      "1016                             Cranberry Sauce Recipe          15   \n",
      "49                           Sugared Cranberries Recipe          63   \n",
      "61                        Cranberry Orange Rolls Recipe         105   \n",
      "9              Cranberry Salsa over Cream Cheese Recipe           5   \n",
      "71                        Orange Cranberry Salsa Recipe          10   \n",
      "490                            Heritage Frosting Recipe          15   \n",
      "653                     Citrus Sorbet with Meyer Lemons          30   \n",
      "\n",
      "                                           Instructions  \\\n",
      "79    Preheat the oven to 400°F.\\r\\nSimmer the orang...   \n",
      "246   Preheat oven to 375º F. Spray muffin tins with...   \n",
      "936   Preheat oven to 325º F.\\r\\nPlace ham into roas...   \n",
      "1016  Bring orange juice, sugar and water to a boil ...   \n",
      "49    Combine 1/2 cup sugar and 1/2 cup water in a m...   \n",
      "61    Cranberry Orange Roll Dough:\\r\\nAdd yeast and ...   \n",
      "9     Add cranberries and sugar to a food processor ...   \n",
      "71    Pulse cranberries and sugar together in a food...   \n",
      "490   Cook flour and milk on low heat until very, ve...   \n",
      "653   Make a simple syrup by heating sugar and water...   \n",
      "\n",
      "                                              Nutrition   Cuisine  \\\n",
      "79    {'calories': '112 kcal', 'carbohydrateContent'...  American   \n",
      "246   {'calories': '278 kcal', 'carbohydrateContent'...  American   \n",
      "936   {'calories': '299 kcal', 'carbohydrateContent'...  American   \n",
      "1016  {'servingSize': '0.25 cup', 'calories': '55 kc...  American   \n",
      "49    {'calories': '164 kcal', 'carbohydrateContent'...  American   \n",
      "61    {'servingSize': '1 g', 'calories': '511 kcal',...  American   \n",
      "9     {'calories': '53 kcal', 'carbohydrateContent':...  American   \n",
      "71    {'calories': '96 kcal', 'carbohydrateContent':...  American   \n",
      "490   {'servingSize': '2 tablespoons', 'calories': '...  American   \n",
      "653   {'servingSize': '0.5 cup', 'carbohydrateConten...  American   \n",
      "\n",
      "           Yields                                        Ingredients  \n",
      "79    12 servings  orange juice, cranberry, orange zest, wheel br...  \n",
      "246   12 servings  , coating cranberry, baking powder, kosher sal...  \n",
      "936   16 servings  ham, cranberry sauce, orange juice, brown suga...  \n",
      "1016   8 servings  cranberry, water, orange juice, sugar, orange ...  \n",
      "49     8 servings                                   sugar, cranberry  \n",
      "61    12 servings  milk, yeast, sugar, butter, kosher salt, egg, ...  \n",
      "9     12 servings  cranberry, sugar, jalapeno pepper, green onion...  \n",
      "71     6 servings  cranberry, sugar, jalapeno pepper, green onion...  \n",
      "490   20 servings        flour, milk, butter, sugar, vanilla extract  \n",
      "653    8 servings  lemon, orange juice, lemon, orange zest, simpl...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_ingredients_str = \"cranberry, orange, butter, sugar\"\n",
    "content_based_recommendations = get_content_based_recommendations(user_ingredients_str)\n",
    "print(content_based_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load datasets\n",
    "recipes_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/recipes_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer with Fine-Tuning\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    ngram_range=(1, 2), \n",
    "    max_df=0.8, \n",
    "    min_df=5,\n",
    "    token_pattern=r'\\b\\w+\\b'\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(recipes_df['Ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(user_ingredients, top_n=10):\n",
    "    user_tfidf = tfidf_vectorizer.transform([user_ingredients])\n",
    "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    similar_indices = cosine_sim.argsort().flatten()[::-1][:top_n]\n",
    "    return recipes_df.iloc[similar_indices]\n",
    "\n",
    "def evaluate_recommendations(user_ingredients, test_ingredients, top_n=10):\n",
    "    recommendations = get_content_based_recommendations(user_ingredients, top_n=top_n)\n",
    "    recommended_ingredients = set(recommendations['Ingredients'].str.split(', ').sum())\n",
    "    test_ingredients_set = set(test_ingredients.split(', '))\n",
    "\n",
    "    true_positives = len(recommended_ingredients & test_ingredients_set)\n",
    "    predicted_positives = len(recommended_ingredients)\n",
    "    actual_positives = len(test_ingredients_set)\n",
    "\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(recipes_df):\n",
    "    train_df, test_df = recipes_df.iloc[train_index], recipes_df.iloc[test_index]\n",
    "    tfidf_vectorizer.fit(train_df['Ingredients'])\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(train_df['Ingredients'])\n",
    "    \n",
    "    for _, test_row in test_df.iterrows():\n",
    "        user_ingredients = train_df.sample(n=1)['Ingredients'].values[0]\n",
    "        test_ingredients = test_row['Ingredients']\n",
    "        precision, recall = evaluate_recommendations(user_ingredients, test_ingredients)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "average_precision = sum(precision_scores) / len(precision_scores)\n",
    "average_recall = sum(recall_scores) / len(recall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.07400032851521744\n",
      "Average Recall: 0.47552593608749427\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Hybrid Recommendation System to Improve Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load datasets\n",
    "recipes_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/recipes_dataset.csv')\n",
    "ratings_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/ratings_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.8, min_df=5)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(recipes_df['Ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(user_ingredients, top_n=10):\n",
    "    user_tfidf = tfidf_vectorizer.transform([user_ingredients])\n",
    "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    similar_indices = cosine_sim.argsort().flatten()[::-1][:top_n]\n",
    "    return recipes_df.iloc[similar_indices]\n",
    "\n",
    "# Function to evaluate recommendations\n",
    "def evaluate_recommendations(user_ingredients, test_ingredients, top_n=10):\n",
    "    recommendations = get_content_based_recommendations(user_ingredients, top_n=top_n)\n",
    "    recommended_ingredients = set(recommendations['Ingredients'].str.split(', ').sum())\n",
    "    test_ingredients_set = set(test_ingredients.split(', '))\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    true_positives = len(recommended_ingredients & test_ingredients_set)\n",
    "    predicted_positives = len(recommended_ingredients)\n",
    "    actual_positives = len(test_ingredients_set)\n",
    "\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0192\n",
      "MAE:  0.7990\n",
      "Collaborative Filtering - RMSE: 1.019232485961972\n",
      "Collaborative Filtering - MAE: 0.7990223389135312\n"
     ]
    }
   ],
   "source": [
    "# Load user ratings\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'recipeId', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Use KNNBasic for collaborative filtering\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Evaluate collaborative filtering model\n",
    "accuracy_rmse = accuracy.rmse(predictions)\n",
    "accuracy_mae = accuracy.mae(predictions)\n",
    "\n",
    "print(f\"Collaborative Filtering - RMSE: {accuracy_rmse}\")\n",
    "print(f\"Collaborative Filtering - MAE: {accuracy_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Filtering - Average Precision: 0.0730352732703867\n",
      "Content-Based Filtering - Average Recall: 0.4800387661475886\n"
     ]
    }
   ],
   "source": [
    "# Example usage with cross-validation for content-based filtering\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(recipes_df):\n",
    "    train_df, test_df = recipes_df.iloc[train_index], recipes_df.iloc[test_index]\n",
    "    tfidf_vectorizer.fit(train_df['Ingredients'])\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(train_df['Ingredients'])\n",
    "    \n",
    "    for _, test_row in test_df.iterrows():\n",
    "        user_ingredients = train_df.sample(n=1)['Ingredients'].values[0]  # Menggunakan satu bahan dari train set\n",
    "        test_ingredients = test_row['Ingredients']  # Bahan dari test set untuk evaluasi\n",
    "        precision, recall = evaluate_recommendations(user_ingredients, test_ingredients)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "average_precision = sum(precision_scores) / len(precision_scores)\n",
    "average_recall = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "print(f\"Content-Based Filtering - Average Precision: {average_precision}\")\n",
    "print(f\"Content-Based Filtering - Average Recall: {average_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Recommendation System\n",
    "def hybrid_recommendations(user_id, user_ingredients, top_n=10):\n",
    "    # Get collaborative filtering recommendations\n",
    "    user_inner_id = algo.trainset.to_inner_uid(user_id)\n",
    "    user_ratings = algo.trainset.ur[user_inner_id]\n",
    "    similar_items = [algo.trainset.to_raw_iid(inner_id) for inner_id in algo.get_neighbors(user_inner_id, k=top_n)]\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = get_content_based_recommendations(user_ingredients, top_n=top_n)\n",
    "    content_recommendation_ids = content_recommendations['recipeId'].tolist()\n",
    "    \n",
    "    # Combine recommendations\n",
    "    combined_recommendations = list(set(similar_items) | set(content_recommendation_ids))\n",
    "    \n",
    "    # Limit to top_n recommendations\n",
    "    combined_recommendations = combined_recommendations[:top_n]\n",
    "    \n",
    "    return recipes_df[recipes_df['recipeId'].isin(combined_recommendations)]\n",
    "\n",
    "# Evaluate Hybrid Recommendations\n",
    "def evaluate_hybrid_recommendations(user_id, user_ingredients, test_ingredients, top_n=10):\n",
    "    recommendations = hybrid_recommendations(user_id, user_ingredients, top_n=top_n)\n",
    "    recommended_ingredients = set(recommendations['Ingredients'].str.split(', ').sum())\n",
    "    test_ingredients_set = set(test_ingredients.split(', '))\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    true_positives = len(recommended_ingredients & test_ingredients_set)\n",
    "    predicted_positives = len(recommended_ingredients)\n",
    "    actual_positives = len(test_ingredients_set)\n",
    "\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Filtering - Average Precision: 0.07223341230436234\n",
      "Hybrid Filtering - Average Recall: 0.4850172125450051\n"
     ]
    }
   ],
   "source": [
    "# Example usage with cross-validation for hybrid filtering\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(recipes_df):\n",
    "    train_df, test_df = recipes_df.iloc[train_index], recipes_df.iloc[test_index]\n",
    "    tfidf_vectorizer.fit(train_df['Ingredients'])\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(train_df['Ingredients'])\n",
    "    \n",
    "    for _, test_row in test_df.iterrows():\n",
    "        user_id = ratings_df.sample(n=1)['userId'].values[0]  # Menggunakan satu user dari dataset ratings\n",
    "        user_ingredients = train_df.sample(n=1)['Ingredients'].values[0]  # Menggunakan satu bahan dari train set\n",
    "        test_ingredients = test_row['Ingredients']  # Bahan dari test set untuk evaluasi\n",
    "        precision, recall = evaluate_hybrid_recommendations(user_id, user_ingredients, test_ingredients)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "average_precision = sum(precision_scores) / len(precision_scores)\n",
    "average_recall = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "print(f\"Hybrid Filtering - Average Precision: {average_precision}\")\n",
    "print(f\"Hybrid Filtering - Average Recall: {average_recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
