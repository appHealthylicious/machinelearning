{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase, PredictionImpossible\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import heapq\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "recipes_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/recipes_dataset.csv')\n",
    "ratings_df = pd.read_csv('C:/Users/arsen/Healthylicious/data/cleaned/csv/ratings_dataset.csv')\n",
    "\n",
    "recipes_df['recipeId'] = recipes_df['recipeId'].astype(int)\n",
    "ratings_df['recipeId'] = ratings_df['recipeId'].astype(int)\n",
    "ratings_df['userId'] = ratings_df['userId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arsen\\Healthylicious\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer and compute TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(','))\n",
    "tfidf_matrix = vectorizer.fit_transform(recipes_df['Ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentKNNAlgorithm(AlgoBase):\n",
    "    def __init__(self, k=40, sim_options={}):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        self.recipes = {row['recipeId']: row for _, row in recipes_df.iterrows()}\n",
    "        self.recipes_index = {row['recipeId']: i for i, row in recipes_df.iterrows()}\n",
    "        \n",
    "        print(\"Computing content-based similarity matrix...\")\n",
    "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
    "        for thisRating in range(self.trainset.n_items):\n",
    "            if (thisRating % 100 == 0):\n",
    "                print(thisRating, \" of \", self.trainset.n_items)\n",
    "            for otherRating in range(thisRating + 1, self.trainset.n_items):\n",
    "                thisRecipeID = int(self.trainset.to_raw_iid(thisRating))\n",
    "                otherRecipeID = int(self.trainset.to_raw_iid(otherRating))\n",
    "                similarity = self.computeContentSimilarity(thisRecipeID, otherRecipeID)\n",
    "                self.similarities[thisRating, otherRating] = similarity\n",
    "                self.similarities[otherRating, thisRating] = similarity\n",
    "        print(\"...done.\")\n",
    "        return self\n",
    "    \n",
    "    def computeContentSimilarity(self, recipe1_id, recipe2_id):\n",
    "        recipe1 = self.recipes[recipe1_id]\n",
    "        recipe2 = self.recipes[recipe2_id]\n",
    "        recipe1_index = self.recipes_index[recipe1_id]\n",
    "        recipe2_index = self.recipes_index[recipe2_id]\n",
    "        ingredient_similarity = cosine_similarity(tfidf_matrix[recipe1_index], tfidf_matrix[recipe2_index]).flatten()[0]\n",
    "        category_similarity = 1 if recipe1['Category'] == recipe2['Category'] else 0\n",
    "        time_diff = abs(recipe1['Total Time'] - recipe2['Total Time'])\n",
    "        time_similarity = np.exp(-time_diff / 10.0)\n",
    "        combined_similarity = 0.2 * ingredient_similarity + 0.6 * category_similarity + 0.2 * time_similarity\n",
    "        return combined_similarity\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unknown.')\n",
    "        neighbors = []\n",
    "        for rating in self.trainset.ur[u]:\n",
    "            content_similarity = self.similarities[i, rating[0]]\n",
    "            neighbors.append((content_similarity, rating[1]))\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
    "        if not k_neighbors:\n",
    "            raise PredictionImpossible('No neighbors')\n",
    "        simTotal = weightedSum = 0\n",
    "        for (simScore, rating) in k_neighbors:\n",
    "            if simScore > 0:\n",
    "                simTotal += simScore\n",
    "                weightedSum += simScore * rating\n",
    "        if simTotal == 0:\n",
    "            raise PredictionImpossible('No neighbors')\n",
    "        predictedRating = weightedSum / simTotal\n",
    "        return predictedRating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing content-based similarity matrix...\n",
      "0  of  1097\n",
      "100  of  1097\n",
      "200  of  1097\n",
      "300  of  1097\n",
      "400  of  1097\n",
      "500  of  1097\n",
      "600  of  1097\n",
      "700  of  1097\n",
      "800  of  1097\n",
      "900  of  1097\n",
      "1000  of  1097\n",
      "...done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ContentKNNAlgorithm at 0x292b4b7d040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert ratings DataFrame to Surprise dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'recipeId', 'rating']], reader)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=1)\n",
    "\n",
    "# Initialize and train the content-based recommender\n",
    "contentKNN = ContentKNNAlgorithm(k=10)\n",
    "contentKNN.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = contentKNN.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0190964729625442\n",
      "MAE: 0.7930028209915896\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "def rmse(predictions):\n",
    "    return np.sqrt(np.mean([(true_r - est_r)**2 for (_, _, true_r, est_r, _) in predictions]))\n",
    "\n",
    "def mae(predictions):\n",
    "    return np.mean([abs(true_r - est_r) for (_, _, true_r, est_r, _) in predictions])\n",
    "\n",
    "print(f'RMSE: {rmse(predictions)}')\n",
    "print(f'MAE: {mae(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(predictions, n=10):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est_r, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est_r))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_recipes(n=10):\n",
    "    recipe_stats = ratings_df.groupby('recipeId').agg({'rating': ['mean', 'count']}).reset_index()\n",
    "    recipe_stats.columns = ['recipeId', 'mean_rating', 'rating_count']\n",
    "    popular_recipes = pd.merge(recipe_stats, recipes_df, on='recipeId')\n",
    "    popular_recipes = popular_recipes.sort_values(['rating_count', 'mean_rating'], ascending=False)\n",
    "    return popular_recipes.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_recommendations = get_top_n_recommendations(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for user 900. Showing popular recipes:\n",
      "Pineapple Upside Down Cake Recipe (average rating: 3.9204819277108434, count: 415)\n",
      "Tomato Pie Recipe (average rating: 4.137592137592137, count: 407)\n",
      "Ham Frittata Recipe (average rating: 4.3138297872340425, count: 376)\n",
      "Lemon Blueberry Pancakes Recipe (average rating: 4.107734806629834, count: 362)\n",
      "Over the Top Hot Chocolate Recipe (average rating: 4.034722222222222, count: 360)\n",
      "Peanut Butter Chocolate Chip Cookies Recipe (average rating: 3.6714697406340058, count: 347)\n",
      "Swedish Meatballs Recipe (average rating: 3.780952380952381, count: 315)\n",
      "Divinity Recipe (average rating: 3.888888888888889, count: 306)\n",
      "Apple Breakfast Cake Recipe (average rating: 3.59672131147541, count: 305)\n",
      "Shortbread Crust Recipe (average rating: 4.152960526315789, count: 304)\n"
     ]
    }
   ],
   "source": [
    "# Display recommendations for a specific user\n",
    "user_id = 900\n",
    "if user_id in top_n_recommendations:\n",
    "    print(f\"Top-10 recommendations for user {user_id}:\")\n",
    "    for recipe_id, estimated_rating in top_n_recommendations[user_id]:\n",
    "        recipe_title = recipes_df[recipes_df['recipeId'] == recipe_id]['Title'].values[0]\n",
    "        print(f\"{recipe_title} (estimated rating: {estimated_rating})\")\n",
    "else:\n",
    "    print(f\"No recommendations for user {user_id}. Showing popular recipes:\")\n",
    "    popular_recipes = get_popular_recipes(n=10)\n",
    "    for _, row in popular_recipes.iterrows():\n",
    "        print(f\"{row['Title']} (average rating: {row['mean_rating']}, count: {row['rating_count']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file using pickle\n",
    "import pickle\n",
    "with open('content_knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(contentKNN, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content_knn_model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model to a file using joblib (as an alternative)\n",
    "import joblib\n",
    "joblib.dump(contentKNN, 'content_knn_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the ratings for user 1 in the training set\n",
    "# user_1_ratings_train = [rating for rating in trainset.ur[trainset.to_inner_uid(1)]]\n",
    "# print(f\"User 1 ratings in training set: {user_1_ratings_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions for user 1 on all items\n",
    "# testset_user_1 = [[1, item, 0] for item in trainset.all_items()]\n",
    "# predictions_user_1 = contentKNN.test(testset_user_1)\n",
    "\n",
    "# # Print the predictions for user 1\n",
    "# for prediction in predictions_user_1:\n",
    "#     print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display top-10 recommendations for another user\n",
    "# user_id = 2 # Change this to a different user ID\n",
    "# top_n_recommendations = get_top_n_recommendations(predictions, n=10)\n",
    "# if user_id in top_n_recommendations:\n",
    "#     print(f\"Top-10 recommendations for user {user_id}:\")\n",
    "#     for recipe_id, estimated_rating in top_n_recommendations[user_id]:\n",
    "#         recipe_title = recipes_df[recipes_df['recipeId'] == recipe_id]['Title'].values[0]\n",
    "#         print(f\"{recipe_title} (estimated rating: {estimated_rating})\")\n",
    "# else:\n",
    "#     print(f\"No recommendations for user {user_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the number of ratings for user 1\n",
    "# user_1_ratings = ratings_df[ratings_df['userId'] == 1]\n",
    "# print(f\"Number of ratings for user 1: {len(user_1_ratings)}\")\n",
    "# print(user_1_ratings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
